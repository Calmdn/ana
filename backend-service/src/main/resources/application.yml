# 服务配置
server:
  port: 8080
  servlet:
    context-path: /logistics-api

spring:
  application:
    name: logistics-analysis-service

  # 数据源配置
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/logistics_db?useSSL=false&serverTimezone=UTC&allowPublicKeyRetrieval=true
    username: root
    password: root

    # Druid连接池配置
    druid:
      initial-size: 5
      min-idle: 5
      max-active: 20
      max-wait: 60000
      validation-query: SELECT 1
      test-while-idle: true

  # Redis配置
  redis:
    host: localhost
    port: 6379
    database: 0
    timeout: 5000ms
    jedis:
      pool:
        max-active: 20
        max-idle: 10
        min-idle: 5
        max-wait: 1000ms

# MyBatis配置
mybatis:
  mapper-locations: classpath:mapper/*.xml
  type-aliases-package: com.logistics.service.dto
  configuration:
    map-underscore-to-camel-case: true

# 物流分析平台配置
logistics:
  spark:
    home: /usr/local/spark
    app-jar: ./spark-analysis/target/spark-analysis-1.0.0.jar
    master: local[*]

  hdfs:
    base-url: hdfs://localhost:9000
    input:
      deliver-path: /user/calmdn/lade/raw/deliver/*.csv
      pickup-path: /user/calmdn/lade/raw/pickup/*.csv
    output:
      base-path: /user/calmdn/lade/results/enhanced-analysis

# 日志配置
logging:
  level:
    com.logistics.service: INFO
    org.apache.spark: WARN
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"